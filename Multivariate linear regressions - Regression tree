# Load the iris dataset
data(iris)
view(iris)                    # Dataset looks complete

iris_model <- Sepal.Length ~ Petal.Length + Petal.Width + factor(Species)
iris_model_no_intercept <- Sepal.Length ~ Petal.Length + Petal.Width + factor(Species) - 1
iris_reg <- lm(iris_model, data=iris)
summary.lm(iris_reg)          # Well well this looks good

# install.packages("stargazer", dependencies = TRUE)
library(stargazer)
stargazer(iris_reg, summary=TRUE, align=TRUE, df = TRUE, intercept.bottom = FALSE, no.space=TRUE, 
          type="html", out="regression summary.doc")
# stargazer(iris_reg, summary=TRUE, align=TRUE, df = TRUE, intercept.bottom = FALSE, no.space=TRUE, 
          type="latex", out="regression summary.tex")          

# Let's get the 90% confidence interval of the regression coefficients and intercept
# Degrees of freedom = n of observations - 1
# The second column of the summary is the standard error of the coeffs
CI_lower <- coefficients(iris_reg) - qt(0.05, df=149)*summary(iris_reg)$coefficients[,2]
CI_upper <- coefficients(iris_reg) + qt(0.05, df=149)*summary(iris_reg)$coefficients[,2]
# Or else: confint(wine_reg, level=0.90)
stargazer(iris_reg, CI_lower, CI_upper, title="Regression  coefficients (with 90% confidence intervals)", 
          column.labels = c("Summary", "Lower limit", "Upper limit"), 
          align=TRUE, no.space=TRUE,
          type = "html", out="Regression coeffs.doc")

# Let's try to improve our model a bit
iris_model2 <- Sepal.Length ~ Petal.Length + Species    # After str(iris$Species) we find that the data are already stored as factors
iris_reg2 <- lm(iris_model2, data=iris)
summary.lm(iris_reg2)        # Meh, we just slightly improve the adj R squared
stargazer(iris_reg, iris_reg2, summary=TRUE, align=TRUE, df = TRUE, intercept.bottom = FALSE, no.space=TRUE, 
          type="html", out="regression comparison.doc")


# Making predictions
newflower <- list(Petal.Length=1.6,Petal.Width=0.2, Species="setosa")
predict.lm(iris_reg, newdata=newflower)
#       1 
#5.131296 
predict.lm(iris_reg2, newdata=newflower)
#      1 
# 5.13083                   # Pretty much the same

# Anova comp
anova(iris_reg, iris_reg2)
# Analysis of Variance Table

# Model 1: Sepal.Length ~ Petal.Length + Petal.Width + factor(Species)
# Model 2: Sepal.Length ~ Petal.Length + factor(Species)
#   Res.Df    RSS Df   Sum of Sq      F Pr(>F)
# 1    145 16.681                             
# 2    146 16.682 -1 -0.00016936 0.0015 0.9694      
# Quick analysis: th p-value of the F-stat is very high, hence removing one variable didn't really improve the model


# Regression tree
# install.packages("rpart")
# install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
simple_model <- Sepal.Length ~ Species
tree <- rpart(simple_model, data=iris, method="class", parms = list(split = "information"))
rpart.plot(tree, extra=101)                    # This basically gives us the frequency of each species in the sample and the average sepal length by species

# Checking the accuracy of the regression tree (CAUTION I HAVEN'T TESTED THIS CODE)
yvalue <- iris$Sepal.Length   # Actual obs
medianlength <- median(iris$Sepal.Length)
yvalue <- ifelse(iris$Sepal.Length > medianlength, 1, 0)
ypred <- predict(tree, type = "vector")
ypred <- as.numeric(ypred> medianlength)

# Confusion matrix
table(Predicted= ypred, Observed = yvalue)

# Perf measures
P <- sum(yvalue == 1)
N <- sum(yvalue == 0)
A <- P + N

TP <- sum((ypred == 1)*(yvalue == 1))
FP <- sum((ypred == 1)*(yvalue == 0))

TN <- sum((ypred == 0)*(yvalue == 0))
FN <- sum((ypred == 0)*(yvalue == 1))

options(digits=3)
cbind(Accuracy = (TP + TN)/(P+N),
      Specificity.TNR = TN/(FP+TN),
      Sensitivity.TPR = TP/(FN+TP),
      FPR = FP/(FP+TN),
      Precision = TP/(FP + TP))
